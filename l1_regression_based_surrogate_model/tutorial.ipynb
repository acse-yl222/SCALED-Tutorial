{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756c69c8",
   "metadata": {},
   "source": [
    "# Welcome to use SCALED\n",
    "\n",
    "SCALED is a diffusion based ai surrogate model for urban flow problem dynamic.\n",
    "For the first tutorial, we will not go into the diffusion based surrogate model, but firstly focused on how to use a simpler regression model with compression to do the inference.\n",
    "We could use a very simple geometry as the test case.\n",
    "To make things simple, at here we will teach you how to use a latent regression model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f90b85",
   "metadata": {},
   "source": [
    "# Preparing for the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07079f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“dvf (Python 3.10.18)”的单元格需要ipykernel包。\n",
      "\u001b[1;31m使用所需的包 <a href='command:jupyter.createPythonEnvAndSelectController'>创建 Python 环境</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib.metadata\n",
    "original_version = importlib.metadata.version\n",
    "importlib.metadata.version = lambda name: \"1.24.4\" if name == \"numpy\" else original_version(name)\n",
    "PROJECT_ROOT1 = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
    "PROJECT_ROOT1 = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "sys.path.insert(0, PROJECT_ROOT1)\n",
    "from scaled.model.unets.unet_3ds import UNet3DsModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scaled.model.unets.unet_3ds import UNet3DsModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scaled.model.autoencoders.autoencoder3dv1 import AutoencoderKL\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd0e296",
   "metadata": {},
   "source": [
    "# Preparing for the basic information for the model to inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic information about domain\n",
    "width = 128\n",
    "height = 128\n",
    "depth = 64\n",
    "compression_weight = 'weight/compression.pth'\n",
    "inference_weight = 'weight/inference.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc052a2",
   "metadata": {},
   "source": [
    "## prepare the model and initialize the model weight\n",
    "For inference we need a compression model and a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91850cc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“dvf (Python 3.10.18)”的单元格需要ipykernel包。\n",
      "\u001b[1;31m使用所需的包 <a href='command:jupyter.createPythonEnvAndSelectController'>创建 Python 环境</a>。"
     ]
    }
   ],
   "source": [
    "# ---- loading the model ----\n",
    "compression_model = AutoencoderKL(\n",
    "    in_channels=3, out_channels=3,\n",
    "    down_block_types=[\"DownEncoderBlock3D\", \"DownEncoderBlock3D\", \"DownEncoderBlock3D\"],\n",
    "    up_block_types=[\"UpDecoderBlock3D\", \"UpDecoderBlock3D\", \"UpDecoderBlock3D\"],\n",
    "    block_out_channels=[128, 256, 384],\n",
    "    latent_channels=4,\n",
    ")\n",
    "compression_model.load_state_dict(torch.load(compression_weight, map_location=\"cpu\"))\n",
    "compression_model.to(device).eval()\n",
    "\n",
    "inference_model = UNet3DsModel(\n",
    "    in_channels=8, out_channels=4,\n",
    "    down_block_types=(\"DownBlock3D\", \"DownBlock3D\", \"DownBlock3D\", \"DownBlock3D\"),\n",
    "    up_block_types=(\"UpBlock3D\", \"UpBlock3D\", \"UpBlock3D\", \"UpBlock3D\"),\n",
    "    block_out_channels=(128, 256, 384, 512),\n",
    "    add_attention=False\n",
    ")\n",
    "inference_model.load_state_dict(torch.load(inference_weight, map_location=\"cpu\"))\n",
    "inference_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55936e19",
   "metadata": {},
   "source": [
    "## Initialize the boundary condition and intial velocity field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.zeros((1,3,depth,height,width)).to('cuda')/3 # we need to divide the value with 3 to normalize the data a little bit.\n",
    "geometry_ = torch.zeros(depth,height,width)\n",
    "geometry_[:,8:-8,8:-8] = torch.tensor(np.load('geo.npy'))[:,8:-8,8:-8]\n",
    "geometry = geometry_.bool()\n",
    "xbc = torch.ones((1, 3, depth, height, width), dtype=torch.float32) # for the area we want to inference we used one as the mask.\n",
    "xbc[:,:,geometry] = 0 # for the geometry location we used zero\n",
    "xbc = xbc.to(device)\n",
    "\n",
    "# we can also asign the boundary condtion into the model\n",
    "## for example:\n",
    "# xbc[:,:1,:] = 0\n",
    "# xbc[:,:1,:] = xbc[:,1:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce7b6a",
   "metadata": {},
   "source": [
    "## Compress the primitive data into latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress the intial flow and the boundary condition into latent\n",
    "latent_x0 = compression_model.encode(x0)/10\n",
    "latent_xbc = compression_model.encode(xbc)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4359d47",
   "metadata": {},
   "source": [
    "## Starting to inference and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(data,step=0):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(data,vmax=1,vmin=-0.5)\n",
    "    plt.title(f\"Timestep {step}\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f'result/{step}.png',dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in tqdm(range(100)):\n",
    "        input = torch.cat([latent_x0,latent_xbc],dim=1)\n",
    "        output = inference_model(input).sample\n",
    "        latent_x0 = output.clone()\n",
    "        decode_latent = compression_model.decode(latent_x0*10)\n",
    "        visualize(decode_latent.detach().cpu().numpy()[0,0,4]*-3,step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
